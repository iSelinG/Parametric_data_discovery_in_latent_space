{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from scipy.interpolate import griddata \n",
    "import torch\n",
    "from util_nets import *\n",
    "from scipy import interpolate\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "\n",
    "\n",
    "def grid_contour(value,coordinates_orig,limit,cmp,vml,fs1=30,cylinder_num=1,saveif=0,filename=None,bar=True):\n",
    "\n",
    "\n",
    "  xmax,xmin,ymax,ymin=limit[0],limit[1],limit[2],limit[3]\n",
    "\n",
    "\n",
    "  dx, dy = 0.005, 0.005\n",
    "  Nx = int((xmax-xmin)/dx+1)\n",
    "  Ny = int((ymax-ymin)/dy+1)\n",
    "  x = np.linspace(xmin, xmax, Nx)\n",
    "  y = np.linspace(ymin, ymax, Ny)\n",
    "  x_mesh, y_mesh = np.meshgrid(x, y)\n",
    "\n",
    "\n",
    "  grid1 = griddata(coordinates_orig,value,(x_mesh,y_mesh), method='linear', fill_value=0)\n",
    "\n",
    "\n",
    "  ddx = 0.5*(x[2]-x[1])\n",
    "  xca = np.linspace(x[0]-ddx, x[len(x)-1]+ddx, len(x)+1)\n",
    "  ddy = 0.5*(y[2]-y[1])\n",
    "  yca = np.linspace(y[0]-ddy, y[len(y)-1]+ddy, len(y)+1)\n",
    "  # vim = [-0.2,1.4]\n",
    "\n",
    "\n",
    "  fit = plt.figure(dpi=300,figsize=(4,2))\n",
    "  ax = plt.axes()\n",
    "\n",
    "  plt.gca().set_aspect('equal')\n",
    "  plt.axis([xmin,xmax,ymin,ymax])\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  if cmp==None:\n",
    "    cmp='viridis'  # 'jet'\n",
    "\n",
    "  if vml==None:\n",
    "    plt.pcolor(xca,yca,grid1[:,:],cmap=cmp)\n",
    "  else:\n",
    "    plt.pcolor(xca,yca,grid1[:,:],cmap=cmp,vmin=vml[0],vmax=vml[1])\n",
    "  plt.xticks(fontsize=fs1-5); plt.yticks(fontsize=fs1-5)  \n",
    "  if cylinder_num==1:\n",
    "    r = 0.05\n",
    "    rx, ry = 0.2, 0.2\n",
    "    cx11=np.linspace(rx-r,rx+r,100)\n",
    "    cy11=np.sqrt(r*r-(cx11-rx)**2)+ry\n",
    "    cx12=np.linspace(rx+r,rx-r,100)\n",
    "    cy12=-np.sqrt(r*r-(cx12-rx)**2)+ry\n",
    "    circx=np.concatenate([cx11,cx12])\n",
    "    circy=np.concatenate([cy11,cy12])\n",
    "    plt.plot(circx,circy,color='black',linewidth=0.1)\n",
    "    c = patches.Circle(xy=(0.2, 0.2), radius=0.05, fc='grey', ec='k')\n",
    "    ax.add_patch(c)\n",
    "  elif cylinder_num==3:\n",
    "    r=0.5\n",
    "    rx, ry = 4.23, 0.8\n",
    "    cx11=np.linspace(rx-r,rx+r,100)\n",
    "    cy11=np.sqrt(r*r-(cx11-rx)**2)+ry\n",
    "    cx12=np.linspace(rx+r,rx-r,100)\n",
    "    cy12=-np.sqrt(r*r-(cx12-rx)**2)+ry\n",
    "    circx=np.concatenate([cx11,cx12])\n",
    "    circy=np.concatenate([cy11,cy12])\n",
    "    plt.plot(circx,circy,color='black',linewidth=1)\n",
    "    c1 = patches.Circle(xy=(rx, ry), radius=r, fc='grey', ec='k')\n",
    "    ax.add_patch(c1)\n",
    "    rx, ry = 4.23, -0.8\n",
    "    cx21=np.linspace(rx-r,rx+r,100)\n",
    "    cy21=np.sqrt(r*r-(cx21-rx)**2)+ry\n",
    "    cx22=np.linspace(rx+r,rx-r,100)\n",
    "    cy22=-np.sqrt(r*r-(cx22-rx)**2)+ry\n",
    "    circx=np.concatenate([cx21,cx22])\n",
    "    circy=np.concatenate([cy21,cy22])\n",
    "    plt.plot(circx,circy,color='black',linewidth=1)\n",
    "    c2 = patches.Circle(xy=(rx, ry), radius=r, fc='grey', ec='k')\n",
    "    ax.add_patch(c2)\n",
    "    rx, ry = 3.0, 0.0\n",
    "    cx31=np.linspace(rx-r,rx+r,100)\n",
    "    cy31=np.sqrt(r*r-(cx31-rx)**2)+ry\n",
    "    cx32=np.linspace(rx+r,rx-r,100)\n",
    "    cy32=-np.sqrt(r*r-(cx32-rx)**2)+ry\n",
    "    circx=np.concatenate([cx31,cx32])\n",
    "    circy=np.concatenate([cy31,cy32])\n",
    "    plt.plot(circx,circy,color='black',linewidth=1)\n",
    "    c3 = patches.Circle(xy=(rx, ry), radius=r, fc='grey', ec='k')\n",
    "    ax.add_patch(c3)\n",
    "  elif cylinder_num==0:\n",
    "    plt.xticks(fontsize=fs1-5); plt.yticks(fontsize=fs1-5)\n",
    "  if bar:\n",
    "    plt.colorbar(fraction=0.1,aspect=50,pad=0.05,orientation='horizontal')\n",
    "  if saveif:\n",
    "    plt.savefig(filename,bbox_inches='tight')\n",
    "  plt.show()\n",
    "  return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 0.0, 0.1, 0.0]\n",
      "(56, 150, 1491, 1)\n",
      "(56, 150, 1491, 1)\n"
     ]
    }
   ],
   "source": [
    "coor = np.load('/root/data1/P-TLDINets/lock-exchange/data/' + 'coor.npy')\n",
    "# coor = np.load('/root/data1/lock-exchange/data/coor.npy')\n",
    "[xmin, ymin] = np.min(coor, axis=0)\n",
    "[xmax, ymax] = np.max(coor, axis=0)\n",
    "limit = [xmax,xmin,ymax,ymin]\n",
    "print(limit)\n",
    "\n",
    "date_str = '04_02_2024_24_52'\n",
    "date_str = '04_03_2024_26_38'\n",
    "date_str = '04_04_2024_26_33save_model_test'\n",
    "date_str = '04_05_2024_22_04save_model_test'\n",
    "\n",
    "\n",
    "results = np.load('/root/data1/P-TLDINets/lock-exchange/results/' + date_str + '/result.npy', allow_pickle=True).item()\n",
    "of_simu = np.load('/root/data1/P-TLDINets/lock-exchange/results/' + date_str + '/of_simu.npy')\n",
    "s_simu = np.load('/root/data1/P-TLDINets/lock-exchange/results/' + date_str + '/s_simu.npy')\n",
    "state = np.load('/root/data1/P-TLDINets/lock-exchange/results/' + date_str + '/state.npy')\n",
    "\n",
    "print(of_simu.shape)\n",
    "\n",
    "print(of_simu.shape)\n",
    "\n",
    "sindy_coef = np.load('/root/data1/P-TLDINets/lock-exchange/results/' + date_str + '/sindy_coef.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = '/root/data1/P-TLDINets/lock-exchange/data/'\n",
    "path_results = '/root/data1/P-TLDINets/lock-exchange/results/'\n",
    "\n",
    "# data_train = np.load(path_data + 'data_train_le_441_150.npy', allow_pickle = True).item()\n",
    "data = np.load(path_data + 'data_test_le_441_150_0-2.npy', allow_pickle = True).item()\n",
    "# data = dataset['X_test']\n",
    "\n",
    "problem = {\n",
    "    'space': {\n",
    "        'dimension' : 2 # lock-exchange problem\n",
    "    },\n",
    "    'input_parameters': [\n",
    "        { 'name': 'coeff_velocity' },\n",
    "        { 'name': 'coeff_viscosity' }\n",
    "    ],\n",
    "    'input_signals': [],\n",
    "    'output_fields': [\n",
    "        { 'name': 'Temperature' }\n",
    "    ]\n",
    "}\n",
    "\n",
    "normalization = {\n",
    "    'space': { 'min' : [-1], 'max' : [+1]},\n",
    "    # 'time': { 'time_constant' : 0.05 },\n",
    "    'input_parameters': {\n",
    "        'coeff_velocity': { 'min': 5.0, 'max': 5.5 },\n",
    "        'coeff_viscosity': { 'min': 1e-6, 'max': 1e-5 },\n",
    "    },\n",
    "    'output_fields': {\n",
    "        'Temperature': { 'min': -1, 'max': +1 }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(of_simu[:, 0, :, 0]), np.min(of_simu[:, 0, :, 0]))\n",
    "print(np.max(data), np.min(data))\n",
    "print(of_simu.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_dataset(data, coor, idx):  # 从data里面sample\n",
    "    new_dataset = {\n",
    "        'points': coor[:, :],  # (1491,2)\n",
    "        'times': data['t'],   # (150,) dt=0.05\n",
    "        'out_fields': data['X_test'][idx, :, :, None],\n",
    "        'inp_parameters': data['param_grid'][idx, :],\n",
    "        'inp_signals': None,\n",
    "    }\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "\n",
    "def process_dataset(dataset, normalization_definition = None, dt = None):\n",
    "    if dt is not None:\n",
    "        times = np.arange(dataset['times'][0], dataset['times'][-1] + dt * 1e-10, step = dt)\n",
    "        if dataset['inp_signals'] is not None:\n",
    "            dataset['inp_signals'] = interpolate.interp1d(dataset['times'], dataset['inp_signals'], axis = 1)(times)\n",
    "        dataset['out_fields'] = interpolate.interp1d(dataset['times'], dataset['out_fields'], axis = 1)(times)\n",
    "        dataset['times'] = times\n",
    "    \n",
    "    num_samples = dataset['out_fields'].shape[0]\n",
    "    num_times = dataset['times'].shape[0]\n",
    "    num_points = dataset['points'].shape[0]\n",
    "    num_x = dataset['points'].shape[1]\n",
    "\n",
    "    points_full = np.broadcast_to(dataset['points'][None,None,:,:], [num_samples, num_times, num_points, num_x])  # (n_sample, n_time, 100, 1) 将space坐标扩展到所有时间和样本点上\n",
    "\n",
    "    # dataset['points_full'] = points_full\n",
    "    dataset['points_full'] = torch.tensor(points_full, dtype=torch.float32)\n",
    "    dataset['num_points'] = dataset['points_full'].shape[2]  # s_dim\n",
    "    dataset['num_times'] = num_times\n",
    "    dataset['num_samples'] = num_samples\n",
    "\n",
    "    \n",
    "        \n",
    "    # dataset['times']\n",
    "    if normalization_definition is not None:\n",
    "        dataset_normalize(dataset, problem, normalization_definition)\n",
    "\n",
    "\n",
    "    dataset['inp_parameters'] = torch.tensor(dataset['inp_parameters'], dtype=torch.float32)\n",
    "    dataset['out_fields'] = torch.tensor(dataset['out_fields'], dtype=torch.float32)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "idx_train = list(range(0, 441, 8))\n",
    "# idx_test =  [idx + 1 for idx in idx_train if idx + 1 <= 440]\n",
    "idx_test =  list(range(0, 441, 1))\n",
    "dataset_train = create_dataset(data, coor, idx_train)\n",
    "dataset_test = create_dataset(data, coor, idx_test)\n",
    "out_fields_normalizetion(dataset_train)\n",
    "out_fields_normalizetion(dataset_test)\n",
    "# process_dataset(dataset_train, dt = 0.5)\n",
    "process_dataset(dataset_train, normalization)\n",
    "process_dataset(dataset_test, normalization)\n",
    "# process_dataset(dataset_train)\n",
    "# process_dataset(dataset_test)\n",
    "\n",
    "\n",
    "\n",
    "train_data = dataset_train['out_fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "num_latent_states = 4\n",
    "coefficient_initialization = 'uniform'\n",
    "poly_order = 1\n",
    "library_dim = library_size(num_latent_states, poly_order)\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out += residual  \n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class NN(nn.Module):\n",
    "    def __init__(self, problem=problem, num_latent_states=num_latent_states):\n",
    "        super(NN, self).__init__()\n",
    "        input_shape = (num_latent_states + len(problem['input_parameters']),)  \n",
    "        # self.dyn = nn.Sequential(\n",
    "        #     nn.Linear(input_shape[0], 9),\n",
    "        #     nn.Tanh(),\n",
    "        #     # ResNetBlock(9, 9),\n",
    "        #     nn.Linear(9, 9),\n",
    "        #     nn.Tanh(),\n",
    "        #     # ResNetBlock(9, 9),\n",
    "        #     nn.Linear(9, 9),\n",
    "        #     nn.Tanh(),\n",
    "        #     # ResNetBlock(9, 9),\n",
    "        #     nn.Linear(9, num_latent_states)\n",
    "        # )\n",
    "        # input_shape = (num_latent_states + problem['space']['dimension'] + len(problem['input_parameters']),)  \n",
    "        # self.rec = nn.Sequential(\n",
    "        #     nn.Linear(input_shape[0], 11),\n",
    "        #     nn.Tanh(),\n",
    "        #     nn.Linear(11, 20),\n",
    "        #     nn.Tanh(),\n",
    "        #     # ResNetBlock(20, 20),\n",
    "        #     nn.Linear(20, 20),\n",
    "        #     nn.Tanh(),\n",
    "        #     # ResNetBlock(20, 20),\n",
    "        #     # nn.Linear(20, 20),\n",
    "        #     # nn.Tanh(),\n",
    "        #     # nn.Linear(20, 20),\n",
    "        #     # nn.Tanh(),\n",
    "        #     # ResNetBlock(20, 20),\n",
    "        #     nn.Linear(20, 11),\n",
    "        #     nn.Tanh(),\n",
    "        #     nn.Linear(11, len(problem['output_fields']))\n",
    "        # )\n",
    "        self.dyn = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 9),\n",
    "            nn.Tanh(),\n",
    "            # ResNetBlock(9, 9),\n",
    "            # nn.Linear(9, 9),\n",
    "            # nn.Tanh(),\n",
    "            ResNetBlock(9, 9),\n",
    "            nn.Linear(9, 9),\n",
    "            nn.Tanh(),\n",
    "            ResNetBlock(9, 9),\n",
    "            nn.Linear(9, num_latent_states)\n",
    "        )\n",
    "        input_shape = (num_latent_states + problem['space']['dimension'] + len(problem['input_parameters']),)  \n",
    "        self.rec = nn.Sequential(\n",
    "            nn.Linear(input_shape[0], 11),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(11, 20),\n",
    "            nn.Tanh(),\n",
    "            ResNetBlock(20, 20),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            ResNetBlock(20, 20),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.Tanh(),\n",
    "            ResNetBlock(20, 20),\n",
    "            nn.Linear(20, 11),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(11, len(problem['output_fields']))\n",
    "        )\n",
    "        for i in range(len(idx_train)):\n",
    "            s_c = torch.nn.Parameter(torch.empty(library_dim, num_latent_states))\n",
    "            if coefficient_initialization == 'uniform':\n",
    "                torch.nn.init.uniform_(s_c)\n",
    "            elif coefficient_initialization == 'constant':\n",
    "                torch.nn.init.constant_(s_c, 0.0)\n",
    "            setattr(self, f'sindy_coef_{i}', s_c)\n",
    "        for i in range(len(idx_train)):\n",
    "            s_c = torch.nn.Parameter(torch.empty(library_dim, num_latent_states))\n",
    "            if coefficient_initialization == 'uniform':\n",
    "                torch.nn.init.uniform_(s_c)\n",
    "            elif coefficient_initialization == 'constant':\n",
    "                torch.nn.init.constant_(s_c, 0.0)\n",
    "            setattr(self, f'sindy_coef_{i}', s_c)\n",
    "\n",
    "        state0 = torch.zeros(num_latent_states,)\n",
    "        self.state0 = nn.Parameter(state0, requires_grad=True)\n",
    "        torch.nn.init.constant_(self.state0, 0.0)\n",
    "\n",
    "    # def NNdyn(self, x):\n",
    "    #     x = self.dyn(x)\n",
    "\n",
    "    # def NNrec(self, x):\n",
    "    #     x = self.rec(x)\n",
    "\n",
    "    def forward(self, x):  \n",
    "        x_ds = self.dyn(x)\n",
    "        x = self.rec(x_ds)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = NN()\n",
    "\n",
    "\n",
    "checkpoint_save = '/root/data1/LDNets-main/lock-exchange/result/' + date_str + \"/checkpoint_last.pth\"  \n",
    "checkpoint = torch.load(checkpoint_save)  # 加载断点\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 150, 4)\n",
      "(56, 150, 1491, 1)\n"
     ]
    }
   ],
   "source": [
    "def model_sindy(sindy_coef, dataset, model, poly_order,  num_latent_states):\n",
    "    if hasattr(model, 'state0'):\n",
    "        state0 = model.state0\n",
    "        state0 = state0.cpu().detach().numpy()  # (num_latent_sates,)\n",
    "        state0 = np.tile(state0, (dataset['num_samples'], 1))\n",
    "    else:\n",
    "        state0 = np.zeros((dataset['num_samples'], num_latent_states), dtype=np.float32)\n",
    "\n",
    "    times = dataset['times']\n",
    "\n",
    "    s_simu = []\n",
    "    # of_simu = []\n",
    "\n",
    "    for k in range(dataset['num_samples']):\n",
    "        s_simu_k = sindy_simulate(state0[k], times, sindy_coef[k], poly_order)\n",
    "        s_simu.append(s_simu_k)\n",
    "    s_simu = np.stack(s_simu, axis=0)\n",
    "\n",
    "    s_simu = torch.tensor(s_simu, dtype=torch.float32)\n",
    "\n",
    "    s_simu_expanded = torch.unsqueeze(s_simu, dim=2) # .to(device)\n",
    "    s_simu_expanded = s_simu_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], num_latent_states)\n",
    "\n",
    "    of_simu = []\n",
    "    inp_para_expanded = dataset['inp_parameters'].unsqueeze(1).unsqueeze(2)\n",
    "    inp_para_expanded = inp_para_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], 2)\n",
    "    input_rec = torch.cat([s_simu_expanded, dataset['points_full'], inp_para_expanded], dim=3)  # (num_sample, n_t, s_dim, 2+\n",
    "    # input_rec = torch.cat([s_simu_expanded, dataset['points_full']], dim=3)  # (num_sample, n_t, s_dim, 2+4)\n",
    "    for i in range(len(input_rec)):\n",
    "        # print(input_rec.device)\n",
    "        # aaa = model.rec(input_rec[i, :, :, :])\n",
    "        # print(aaa.device)\n",
    "        of_simu.append(model.rec(input_rec[i, :, :, :]).cpu().detach().numpy())\n",
    "    \n",
    "    of_simu = np.stack(of_simu)\n",
    "    # print('of_simu', of_simu.shape)\n",
    "\n",
    "    return s_simu, of_simu\n",
    "\n",
    "model = model.to('cpu')\n",
    "s_simu, of_simu = model_sindy(sindy_coef, dataset_train, model, poly_order,  num_latent_states)\n",
    "s_simu = s_simu.cpu().detach().numpy()\n",
    "print(s_simu.shape)\n",
    "print(of_simu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.05\n",
    "\n",
    "\n",
    "\n",
    "def evolve_dynamics(dataset, model, dt): \n",
    "    # num_samples = len(dataset['inp_parameters'])\n",
    "    # state = torch.zeros((dataset['num_samples'], num_latent_states), dtype=torch.float32).to(device)  # (100,2)  /  (147, 3)\n",
    "    if hasattr(model, 'state0'):\n",
    "        state0 = model.state0\n",
    "        state0_expand = torch.unsqueeze(state0, 0)\n",
    "        state = state0_expand.repeat(dataset['num_samples'], 1)\n",
    "    else:\n",
    "        state = torch.zeros((dataset['num_samples'], num_latent_states), dtype=torch.float32).to(device)  # (100,2)  /  (147, 3)\n",
    "    \n",
    "    state_history = []\n",
    "    state_history.append(state)  # s(t_0).shape=(n_sample,n_z)=0\n",
    "    d_state_history = []\n",
    "    # dt_ref = normalization['time']['time_constant']\n",
    "    dt_ref = 1\n",
    "\n",
    "    for _ in range(dataset['num_times'] - 1):\n",
    "        d_state = model.dyn(torch.cat([state, dataset['inp_parameters']], dim=-1))\n",
    "        d_state_history.append(d_state)  \n",
    "        state = state + dt / dt_ref * d_state   \n",
    "        state_history.append(state)  \n",
    "    \n",
    "    d_state = model.dyn(torch.cat([state, dataset['inp_parameters']], dim=-1))\n",
    "    d_state_history.append(d_state)\n",
    "        \n",
    "    \n",
    "    ds_t = torch.stack(d_state_history).permute(1, 0, 2)\n",
    "    s_t = torch.stack(state_history).permute(1, 0, 2)\n",
    "    \n",
    "    # return torch.stack(state_history).permute(1, 0, 2)  # (n_sample,n_t,n_latent_state) s(t)\n",
    "    return ds_t, s_t\n",
    "\n",
    "\n",
    "def reconstruct_output(dataset, states, model):\n",
    "    states_expanded = torch.unsqueeze(states, dim=2) # .to(device)\n",
    "    states_expanded = states_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], num_latent_states)\n",
    "    inp_para_expanded = dataset['inp_parameters'].unsqueeze(1).unsqueeze(2)\n",
    "    inp_para_expanded = inp_para_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], 2)\n",
    "    # states_expanded = tf.broadcast_to(tf.expand_dims(states, axis = 2), \n",
    "    #     [dataset['num_samples'], dataset['num_times'], dataset['num_points'], num_latent_states])  # (100,101,1,2)→(n_sample100,n_t101,s_dim100,2) 在空间维度复制s_dim次\n",
    "    # ccc = torch.cat([states_expanded, dataset['points_full']], dim=3)\n",
    "    return model.rec(torch.cat([states_expanded, dataset['points_full'], inp_para_expanded], dim=3)) # NNrec(s(t),x)=y/z  s(t)(n_sample,n_t,2)+x(s_dim,) → (n_sample,n_t,s_dim,3) → (n_sample,n_t,s_dim,1)\n",
    "\n",
    "def LDNet(dataset, model, dt):\n",
    "    d_states, states = evolve_dynamics(dataset, model, dt)  \n",
    "    return d_states, states, reconstruct_output(dataset, states, model)  # y(x,t)=(n_sample,n_t,s_dim,1)\n",
    "\n",
    "def MSE(dataset, model, dt):\n",
    "    d_states, state, out_fields = LDNet(dataset, model, dt)\n",
    "    error = out_fields - dataset['out_fields']  # (n_sample, n_t, s_dim, 1)\n",
    "    # print(out_fields) ×\n",
    "    # print(state) √\n",
    "\n",
    "    return d_states, state, error # torch.mean(torch.square(error))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    d_state2, state2, error2 = MSE(dataset_train, model, dt)\n",
    "    d_states4, state4, out_fields4 = LDNet(dataset_train, model, dt)\n",
    "state2 = state2.cpu().detach().numpy()\n",
    "d_state2 = d_state2.cpu().detach().numpy()\n",
    "# print(out_fields4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_state, state2 = evolve_dynamics(dataset_train, model, dt)\n",
    "# model = model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    d_state2, state2, error2 = MSE(dataset_train, model, dt) \n",
    "state2 = state2.cpu().detach().numpy()\n",
    "d_state2 = d_state2.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(next(model.parameters()).device)\n",
    "param_train = dataset_train['inp_parameters']\n",
    "param_train = param_train.cpu().detach().numpy()\n",
    "# param_train.shape\n",
    "print(np.max(param_train[:, 0]), np.min(param_train[:, 0]))\n",
    "print(np.max(param_train[:, 1]), np.min(param_train[:, 1]))\n",
    "\n",
    "if len(problem.get('input_parameters', [])) > 0:  # 3>0\n",
    "    inp_parameters_min = np.array([normalization['input_parameters'][v['name']]['min'] for v in problem['input_parameters']])  # (2,)\n",
    "    inp_parameters_max = np.array([normalization['input_parameters'][v['name']]['max'] for v in problem['input_parameters']])  # (2,)\n",
    "def normalize_back_para(v, v_min, v_max, axis = None, mode = 1, v_range = 1):\n",
    "    v_min, v_max = reshape_min_max(len(v.shape), v_min, v_max, axis)\n",
    "    if mode == 1:\n",
    "        return 0.5 * v * (v_max - v_min)  / v_range + (v_min + v_max) \n",
    "    elif mode == 2:\n",
    "        return v * (v_max- v_min) + v_min\n",
    "    \n",
    "param_train_back = normalize_back_para(param_train, inp_parameters_min, inp_parameters_max, axis = 1, mode=2)\n",
    "param_train\n",
    "\n",
    "print(np.max(param_train[:, 0]), np.min(param_train[:, 0]))\n",
    "print(np.max(param_train[:, 1]), np.min(param_train[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = dataset_train['times']\n",
    "param_grid = dataset_train['inp_parameters']\n",
    "out_fields_train = dataset_train['out_fields'].cpu().detach().numpy()\n",
    "\n",
    "index = 0\n",
    "\n",
    "\n",
    "in_train_idx = True\n",
    "\n",
    "for index in range(0, dataset_train['num_samples']):\n",
    "    # if index in idx_train:\n",
    "    #     in_train_idx = True\n",
    "    # else:\n",
    "    #     in_train_idx = False\n",
    "    print(index, param_grid[index, :], param_train_back[index, :]) # , in_train_idx)\n",
    "    print(1 - np.linalg.norm((of_simu[index, :, :, 0] - out_fields_train[index,:, :, 0]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :, 0]).reshape(-1,1), ord=2), end = ' ')\n",
    "    # print(1 - np.linalg.norm((uu_simu[index, :, :] - out_fields_train[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :]).reshape(-1,1), ord=2), end = ' ')\n",
    "    print(1 - np.linalg.norm((of_simu[index, :, :, 0] - out_fields_train[index,:, :, 0]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :, 0]).reshape(-1,1), ord=2), end = ' ')\n",
    "    print(1 - np.linalg.norm((s_simu[index, :, :] - state[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((state[index, :, :]).reshape(-1,1), ord=2))\n",
    "    print(1 - np.linalg.norm((s_simu[index, :, :] - state2[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((state2[index, :, :]).reshape(-1,1), ord=2))\n",
    "\n",
    "    # fig=plt.figure(dpi=300,figsize=(6,2))\n",
    "    fig=plt.figure(dpi=300,figsize=(4,3))\n",
    "    for kk in range(state.shape[-1]):\n",
    "        plt.plot(t, state[index,:,kk],lw=1.0, label='r' + str(kk))\n",
    "        # plt.plot(t, state2[index,:,kk], '--', label='r2' + str(kk))\n",
    "        # plt.plot(t, s_simu[index,:,kk], '.-', ms=2, lw=1.0, label='r'+str(kk)+'_')\n",
    "        plt.plot(t, s_simu[index,:,kk], '--', ms=2, lw=1.0, label='r'+str(kk)+'_')\n",
    "\n",
    "    plt.yticks([-1.0, -0.5, 0.0, 0.5, 1.0], ['-1.0', '-0.5', '0.0', '0.5', '1.0'])\n",
    "    plt.xticks([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0'])\n",
    "\n",
    "\n",
    "    # plt.xlim([4.0,6.0])\n",
    "    plt.legend(loc='lower right', fontsize=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0001917 -5.0261617\n"
     ]
    }
   ],
   "source": [
    "of_simu2 = of_simu\n",
    "\n",
    "def out_fields_reverse(dataset, of_simu):\n",
    "    param_grid = dataset['inp_parameters'].cpu().detach().numpy()\n",
    "    out_fields_max = param_grid[:, 0]\n",
    "    out_fields_min = -param_grid[:, 0]\n",
    "    of_simu = (5 + of_simu) / 10 * (out_fields_max - out_fields_min)[:, np.newaxis, np.newaxis, np.newaxis]  + out_fields_min[:, np.newaxis, np.newaxis, np.newaxis]\n",
    "    return of_simu\n",
    "\n",
    "# of_simu2 = out_fields_reverse(dataset_train, of_simu2)\n",
    "print(np.max(of_simu2), np.min(of_simu2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "0.2 -0.2\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters()).device)\n",
    "param_train = dataset_train['inp_parameters']\n",
    "param_train = param_train.cpu().detach().numpy()\n",
    "# param_train.shape\n",
    "print(np.max(param_train[:, 0]), np.min(param_train[:, 0]))\n",
    "print(np.max(param_train[:, 1]), np.min(param_train[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "X_train = dataset_train['out_fields']  # (55, 150, 1491, 1)\n",
    "X_test = dataset_test['out_fields']  # (55, 150, 1491, 1)\n",
    "X_test.shape\n",
    "sindy_coef = []\n",
    "for i in range(len(dataset_train['inp_parameters'])):\n",
    "    sindy_coef_i = getattr(model, f'sindy_coef_{i}')\n",
    "    sindy_coef.append(sindy_coef_i.cpu().detach().numpy())\n",
    "print(len(sindy_coef))\n",
    "\n",
    "state0 = model.state0\n",
    "state0 = state0.cpu().detach().numpy()\n",
    "print(state0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "(56, 150, 4)\n"
     ]
    }
   ],
   "source": [
    "times = dataset_train['times']\n",
    "n_train = len(sindy_coef)\n",
    "n_t = len(times)\n",
    "n_points = dataset_train['num_points']\n",
    "poly_order = 1\n",
    "\n",
    "\n",
    "s_simu_train = []\n",
    "    # of_simu = []\n",
    "\n",
    "for k in range(n_train):\n",
    "    s_simu_k = sindy_simulate(state0, times, sindy_coef[k], poly_order)\n",
    "    s_simu_train.append(s_simu_k)\n",
    "    # print(k)\n",
    "print(len(s_simu_train))\n",
    "s_simu_train = np.stack(s_simu_train, axis=0)  # (n_train, n_t, num_latent_states)\n",
    "print(s_simu_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sindy_coef_test = []\n",
    "param_test = dataset_test['inp_parameters']\n",
    "param_test = param_test.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## knn interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict for sindy coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sindy_coef(sindy_coef_train, param_train, param_test, t_grid, Z0, poly_order=1, knn=4):\n",
    "    num_train = len(sindy_coef_train)  # =len(param_train)\n",
    "    if num_train < 4:\n",
    "        knn = 1\n",
    "    \n",
    "    sindy_coeff = []\n",
    "\n",
    "    for k in range(len(param_test)):\n",
    "        if knn == 1:  \n",
    "            idx = np.argmin(np.linalg.norm(param_train-param_test[k], axis=1))  \n",
    "            sindy_coef_k = sindy_coef_train[idx]  \n",
    "        else:\n",
    "            dist = np.linalg.norm(param_train-param_test[k], axis=1) \n",
    "            knn_idx = np.argsort(dist)[:knn]\n",
    "            phi = np.zeros_like(knn_idx)\n",
    "\n",
    "            if dist[knn_idx[0]] == 0: \n",
    "                phi[0] = 1  \n",
    "            else:\n",
    "                phi = 1 / np.linalg.norm(param_train[knn_idx]-param_test[k], axis=1)**1\n",
    "            psi = phi / phi.sum()\n",
    "\n",
    "            sindy_coef_k = np.zeros_like(sindy_coef_train[0])\n",
    "            for i, kidx in enumerate(knn_idx):\n",
    "                sindy_coef_k += psi[i] * sindy_coef_train[kidx]\n",
    "        \n",
    "        sindy_coeff.append(sindy_coef_k)\n",
    "\n",
    "    return sindy_coeff\n",
    "\n",
    "# sindy_coef_test = eval_sindy_coef(sindy_coef, param_train, param_test, times, state0, poly_order=1, knn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(sindy_coef_train, dataset, param_train, param_test, t_grid, Z0, model, poly_order=1, knn=4):\n",
    "    sindy_coef_test = eval_sindy_coef(sindy_coef_train, param_train, param_test, t_grid, Z0, poly_order, knn)\n",
    "    # print(len(param_test))\n",
    "    # print('sindy_coef_test', len(sindy_coef_test), sindy_coef_test[0].shape)\n",
    "    s_simu = []\n",
    "    of_simu = []\n",
    "    for k in range(len(param_test)):  \n",
    "        if len(Z0.shape) < 2: \n",
    "            s_simu_k = sindy_simulate(Z0, t_grid, sindy_coef_test[k], poly_order)\n",
    "        elif len(Z0.shape) == 2:\n",
    "            s_simu_k = sindy_simulate(Z0[k], t_grid, sindy_coef_test[k], poly_order)\n",
    "        s_simu.append(s_simu_k)\n",
    "    s_simu = np.stack(s_simu, axis=0)\n",
    "\n",
    "    s_simu_tensor = torch.tensor(s_simu, dtype=torch.float32)\n",
    "\n",
    "    s_simu_expanded = torch.unsqueeze(s_simu_tensor, dim=2) # .to(device)\n",
    "    s_simu_expanded = s_simu_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], num_latent_states)\n",
    "\n",
    "    of_simu = []\n",
    "    inp_para_expanded = dataset['inp_parameters'].unsqueeze(1).unsqueeze(2)\n",
    "    inp_para_expanded = inp_para_expanded.expand(dataset['num_samples'], dataset['num_times'], dataset['num_points'], 2)\n",
    "    input_rec = torch.cat([s_simu_expanded, dataset['points_full'], inp_para_expanded], dim=3)  # (num_sample, n_t, s_dim, 2+\n",
    "    # input_rec = torch.cat([s_simu_expanded, dataset['points_full']], dim=3)  # (num_sample, n_t, s_dim, 2+4)\n",
    "    for i in range(len(input_rec)):\n",
    "        of_simu.append(model.rec(input_rec[i, :, :, :]).cpu().detach().numpy())\n",
    "    of_simu = np.stack(of_simu)\n",
    "\n",
    "    return s_simu, of_simu, sindy_coef_test\n",
    "\n",
    "\n",
    "sindy_coef_train = sindy_coef\n",
    "param_test = dataset_test['inp_parameters'].cpu().detach().numpy()\n",
    "s_simu_test, of_simu_test, sindy_coef_test = eval_model(sindy_coef_train, dataset_test, param_train, param_test, times, state0, model, knn=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### draw test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = dataset_test['times']\n",
    "param_test = dataset_test['inp_parameters']\n",
    "out_fields_test = dataset_test['out_fields'].cpu().detach().numpy()\n",
    "\n",
    "index = 0\n",
    "\n",
    "\n",
    "in_train_idx = True\n",
    "param_test_back = normalize_back_para(param_test, inp_parameters_min, inp_parameters_max, axis = 1, mode=2)\n",
    "\n",
    "for index in range(0, dataset_test['num_samples']):\n",
    "    # if index in idx_train:\n",
    "    #     in_train_idx = True\n",
    "    # else:\n",
    "    #     in_train_idx = False\n",
    "    print(index, param_test[index, :], param_test_back[index, :]) # , in_train_idx)\n",
    "    print(1 - np.linalg.norm((of_simu[index, :, :, 0] - out_fields_train[index,:, :, 0]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :, 0]).reshape(-1,1), ord=2), end = ' ')\n",
    "    # print(1 - np.linalg.norm((uu_simu[index, :, :] - out_fields_train[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :]).reshape(-1,1), ord=2), end = ' ')\n",
    "    print(1 - np.linalg.norm((of_simu[index, :, :, 0] - out_fields_train[index,:, :, 0]).reshape(-1,1), ord=2) / np.linalg.norm((out_fields_train[index, :, :, 0]).reshape(-1,1), ord=2), end = ' ')\n",
    "    print(1 - np.linalg.norm((s_simu[index, :, :] - state[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((state[index, :, :]).reshape(-1,1), ord=2))\n",
    "    print(1 - np.linalg.norm((s_simu[index, :, :] - state2[index,:, :]).reshape(-1,1), ord=2) / np.linalg.norm((state2[index, :, :]).reshape(-1,1), ord=2))\n",
    "\n",
    "    # fig=plt.figure(dpi=300,figsize=(6,2))\n",
    "    fig=plt.figure(dpi=300,figsize=(4,3))\n",
    "    for kk in range(state.shape[-1]):\n",
    "        plt.plot(t, state[index,:,kk],lw=1.0, label='r' + str(kk))\n",
    "        # plt.plot(t, state2[index,:,kk], '--', label='r2' + str(kk))\n",
    "        # plt.plot(t, s_simu[index,:,kk], '.-', ms=2, lw=1.0, label='r'+str(kk)+'_')\n",
    "        plt.plot(t, s_simu[index,:,kk], '--', ms=2, lw=1.0, label='r'+str(kk)+'_')\n",
    "\n",
    "    plt.yticks([-1.0, -0.5, 0.0, 0.5, 1.0], ['-1.0', '-0.5', '0.0', '0.5', '1.0'])\n",
    "    plt.xticks([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], ['0.0', '1.0', '2.0', '3.0', '4.0', '5.0', '6.0', '7.0'])\n",
    "\n",
    "\n",
    "    # plt.xlim([4.0,6.0])\n",
    "    plt.legend(loc='lower right', fontsize=5)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
